#!/usr/bin/env bash

source message_functions || exit 1
source locate_files || exit 1

script="$(basename "$0")"

print_usage() {
cat <<EOM
-----
 Descr: Verifies a Somatic pipeline run
 Usage: $script [required arguments] [optional arguments]
 Required arguments:
   --out_dir [s]              Output directory
   --truth_run_dir [s]        Input directory containing truth run
   --truth_db_schema [s]      Name of schema in verification DB (eg "hmfpatients_5_27")
   --new_run_dir [s]          Input directory containing new run
   --new_db_schema [s]        Name of schema in verification DB (eg "hmfpatients_5_28")
 Optional arguments:
   --disable_sanity_checks    Disable extra checks
   --disable_schema_checks    Assume required schemas are in place and do not explicitly check for them
-----
EOM
    exit 1
}

sanity_checks="TRUE"
schema_checks="TRUE"
args=$(getopt -o "" --longoptions disable_sanity_checks,disable_schema_checks,out_dir:,truth_run_dir:,truth_db_schema:,new_run_dir:,new_db_schema: -- "$@")
[[ $? != 0 ]] && echo "Bad arguments" && exit 1
eval set -- "$args"

while true; do
    case "$1" in
        --out_dir) out_dir=${2} ; shift 2 ;;
        --truth_run_dir) truth_run_dir=${2} ; shift 2 ;;
        --truth_db_schema) truth_db_schema=${2} ; shift 2 ;;
        --new_run_dir) new_run_dir=${2} ; shift 2 ;;
        --new_db_schema) new_db_schema=${2} ; shift 2 ;;
        --disable_sanity_checks) sanity_checks="FALSE"; shift ;;
        --disable_schema_checks) schema_checks="FALSE"; shift ;;
        -- ) shift; break ;;
    esac
done

if [[ -z "${out_dir}" || -z "${truth_run_dir}" || -z "${new_run_dir}" || -z "${truth_db_schema}" || -z "${new_db_schema}" ]]; then
    echo "Missing arguments!"
    print_usage
fi

main() {
    info "Starting with script $script"

    truth_run=$(realpath "$truth_run_dir")
    new_run=$(realpath "$new_run_dir")
    
    ## some input sanity checks
    [[ -n "${out_dir}" && "${out_dir}" =~ ^\/ ]] || die "Incorrect out_dir format (${out_dir})?"
    [[ -d "${new_run}" ]] || die "New run dir not found (${new_run})"
    [[ -f "${new_run}/pipeline.version" ]] || die "Pipeline version file missing (in new run: ${new_run})"
    [[ -d "${truth_run}" ]] || die "Truth run dir not found (${truth_run})"
    if [[ "${sanity_checks}" == "TRUE" ]]; then
        [[ ! -d "${out_dir}" ]] || die "Output dir exists (${out_dir})"
    fi

    info "Constructing variables"
    truth_run_name=$(basename "${truth_run}")
    new_run_name=$(basename "${new_run}")
    jobs_dir="${out_dir}/jobs"
    logs_dir="${out_dir}/logs"

    truth_metadata_file="${truth_run}/metadata.json"
    new_metadata_file="${new_run}/metadata.json"
    truth_metadata_content=$(cat "${truth_metadata_file}")
    new_metadata_content=$(cat "${new_metadata_file}")
    info "Diffing metadata jsons"
    diff_metadata_jsons "${truth_metadata_content}" "${new_metadata_content}"
    info "Checking format of ${truth_metadata_file}"
    check_metadata_json_content "${truth_metadata_file}"
    info "Checking format of ${new_metadata_file}"
    check_metadata_json_content "${new_metadata_file}"

    truth_sample=$(jq -r '.tumor.sampleName' "${truth_metadata_file}")
    new_sample=$(jq -r '.tumor.sampleName' "${new_metadata_file}")

    info "Config:"
    info "  Output path: ${out_dir}"
    info "  Jobs directory: ${jobs_dir}"
    info "  Logs directory: ${logs_dir}"
    info "  Truth run: ${truth_run_name} (sample=${truth_sample})"
    info "  New run: ${new_run_name} (sample=${new_sample})"

    info "Creating directory structure"
    mkdir -p "${out_dir}" "${jobs_dir}" "${logs_dir}" || die "Unable to create dirs"
    cd "${out_dir}" || die "Unable to move to output directory"

    info "Gathering script and sql job files"
    jobs_source_path="/data/repos/scripts/validation"
    script_jobs=(
        "compare_v5_runs"
        "run_all_sql_verification_jobs"
    )
    sql_jobs=(
        "check_update_time.sql"
        "compare_metrics.sql"
        "compare_purity.sql"
        "diff_summary.sql"
        "diff_amberSample.sql"
        "diff_chord.sql"
        "diff_flagstat.sql"
        "diff_germlineVariant.sql"
        "diff_peachCalls.sql"
        "diff_peachGenotype.sql"
        "diff_protect.sql"
        "diff_somaticVariant.sql"
        "diff_structuralVariant.sql"
        "diff_svBreakend.sql"
        "diff_virusAnnotation.sql"
        "diff_virusBreakend.sql"
        "diff_driverCatalog.sql"
    )
    for job_file_name in "${script_jobs[@]}" "${sql_jobs[@]}"; do
        copy_file "${jobs_source_path}/${job_file_name}" "${jobs_dir}"
    done
    copy_file "/data/repos/scripts/functions/test/locate_files_test" "${jobs_dir}"

    # Somewhat hacky way of replacing the variables of template SQL
    info "Replacing variables in SQL job files"
    for sql_file_name in "${sql_jobs[@]}"; do
        sed -i "s/VARIABLE_TRUTH_SAMPLE_ID/${truth_sample}/g" "${jobs_dir}/${sql_file_name}"
        sed -i "s/VARIABLE_NEW_SAMPLE_ID/${new_sample}/g" "${jobs_dir}/${sql_file_name}"
        sed -i "s/VARIABLE_TRUTH_DB_SCHEMA/${truth_db_schema}/g" "${jobs_dir}/${sql_file_name}"
        sed -i "s/VARIABLE_NEW_DB_SCHEMA/${new_db_schema}/g" "${jobs_dir}/${sql_file_name}"
    done

    grep_for="err|warn|exit|excep"
    info "Looking for anomalies in run.log files (searching for ${grep_for})"
    find "${new_run}" -name "run.log" -exec grep -Pi "${grep_for}" {} + \
      | grep -v germline_caller > "${logs_dir}/runlogs_check.txt"

    info "Executing locate_files test"
    "${jobs_dir}/locate_files_test" "${new_run}" > "${logs_dir}/locate_files_test.log" 2>&1

    info "Setting up SQL check"
    sql_query_script="run_all_sql_verification_jobs"
    sql_query_job="${jobs_dir}/${sql_query_script}"
    sql_checks_job="${jobs_dir}/run_sql_jobs_after_db_load"
    echo "${sql_query_job} ${jobs_dir} ${logs_dir} ${new_db_schema}" > "${sql_checks_job}"
    chmod +x "${sql_checks_job}"
    out_log="${logs_dir}/${sql_query_script}.log"
    err_log="${logs_dir}/${sql_query_script}.err"
    if [[ "${schema_checks}" == "TRUE" && ! $(db_schema_exists_and_sample_present "${truth_db_schema}" "${truth_sample}") ]]; then
        warn "Failed checks for schema [${truth_db_schema}] so unable to perform SQL check"
    elif [[ "${schema_checks}" == "TRUE" && ! $(db_schema_exists_and_sample_present "${new_db_schema}" "${new_sample}") ]]; then
        warn "Failed checks for schema [${new_db_schema}] so unable to perform SQL check"
    else
        info "Executing ${sql_query_script}"
        "${sql_checks_job}" > "${out_log}" 2>"${err_log}"
    fi

    info "Executing compare_v5_runs"
    out_log="${logs_dir}/compare_v5_runs.log"
    err_log="${logs_dir}/compare_v5_runs.err"
    "${jobs_dir}/compare_v5_runs" "${truth_run}" "${new_run}" > "${out_log}" 2>"${err_log}"

    info "TODO NEXT: Inspect all log files in ${logs_dir}"
    info "Finished with $script"
}

db_schema_exists_and_sample_present() {
    local schema=$1 && shift
    local sample=$1 && shift
    exec_script="execute_sql_on_pipeline_verification_db"
    schema_query="SELECT COUNT(SCHEMA_NAME) FROM INFORMATION_SCHEMA.SCHEMATA WHERE SCHEMA_NAME = '${schema}'"
    sample_query="SELECT COUNT(*) FROM ${schema}.purity WHERE sampleId = '${sample}'"
    if [[ ! $("$exec_script" "$schema" "$schema_query" | tail -1) -eq 1 ]]; then
        warn "DB schema not found [$schema]"
        return 1
    fi
    if [[ ! $("$exec_script" "$schema" "$sample_query" | tail -1) -eq 1 ]]; then
        warn "Sample [$sample] not found in purity table of schema [$schema]"
        return 1
    fi
    info "OK: DB schema [$schema] found with sample [$sample] present"
    return 0
}

copy_file() {
    local file_path=$1 && shift
    local target_dir=$1 && shift

    if [[ ! -f "${file_path}" ]]; then
        die "File not found (${file_path})"
    else
        info "  OK copied file ($file_path)"
        cp "${file_path}" "${jobs_dir}" || die "Unable to copy file (${file_path}) to dir (${target_dir})"
    fi
}

diff_metadata_jsons() {
    local json1=$1 && shift
    local json2=$1 && shift

    diff_count=$(diff \
      <(jq 'del(.set, .bucket, .reference.samplingDate, .reference.set, .tumor.set, .reference.bucket, .tumor.samplingDate, .tumor.bucket, .external_ids)' <<< "${json1}") \
      <(jq 'del(.set, .bucket, .reference.samplingDate, .reference.set, .tumor.set, .reference.bucket, .tumor.samplingDate, .tumor.bucket, .external_ids)' <<< "${json2}") \
    | wc -l)

    if [[ "${diff_count}" -eq 0 ]]; then
        info "  OK metadata diff is 0"
    else
        warn "  Difference found between metadata jsons"
    fi
}

check_metadata_json_content() {
    local metadata_json=$1 && shift
    fields_to_check=(
        '.set'
        '.reference.sampleName'
        '.reference.barcode'
        '.tumor.sampleName'
        '.tumor.barcode'
        '.tumor.primaryTumorDoids'
    )
    all_fields_present=TRUE
    for field in ${fields_to_check[*]}; do
        if [[ $(jq "select(${field} == null)" "${metadata_json}") ]]; then
            warn "  Field ${field} absent metadata (${metadata_json})"
            all_fields_present=FALSE
        fi
    done
    if [[ "${all_fields_present}" == "TRUE" ]]; then
        info "  OK field found in metadata (${field})"
    fi

    # specific check on COLO doid
    tumor_name=$(jq '.tumor.sampleName' "${metadata_json}")
    expected_doid="8923"
    if [[ "$tumor_name" =~ COLO829 ]]; then
        doid=$(jq -r '.tumor.primaryTumorDoids | join(",")' "${metadata_json}")
        if [[ "${doid}" == "${expected_doid}" ]]; then
            info "  OK found expected tumor DOIDs '${expected_doid}' in metadata json"
        else
            warn "  Expected tumor DOIDs '${expected_doid}' but found '${doid}' instead"
        fi
    fi
}

main
